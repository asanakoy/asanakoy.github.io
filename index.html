<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0//EN">
<html>
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-24712354-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-24712354-1');
</script>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="keywords" content="Computer Vision, Deep Learning, Metric Learning, Representation Learning">
<meta name="author" content="Artsiom Sanakoyeu">
<title>Artsiom Sanakoyeu • Computer Vision Researcher</title>
    
<style type="text/css">
	body
	{
		width:100%;
		text-align: center;
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-size:16px;
		background-color: #FFF;
	}
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

	table
	{
		padding: 5px;
	}

	table.pub_table,td.pub_td1,td.pub_td2
	{
		border-collapse: collapse;
		border-bottom: 0px solid #9B9B9B;
		padding-bottom: 10px;
		padding-top: 10px;
		padding-left: 10px;
		width: 950px;
	}
	td.pub_td1
	{
		width:100px;
	}
	td.pub_td2
	{
	}
	td.year_heading
	{
		color: #3B3B3B;
		font-weight: 700;
		font-size:20px;
	}
	tr {
		background-color: #FFF;
	}

	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 1200px;
		text-align: left;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		color: #9B9B9B;
		height: 128px;
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h2
	{
		font-size:130%;
	}
	p
	{
		color: #000;
		margin-bottom: 20px;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
		font:11px helvetica,sans-serif;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
		font:11px helvetica,sans-serif;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
	}
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	.section_div {
		background-color: #FFF;
		padding: 10px 10px 10px 10px;
		margin: 10px 10px 10px 10px;
		//border: 1px solid #AAA;
	}
	body {
		background-color: #FFF;
	}
	#personal_info {
		background-color: #FFF;
	}
    div#news p {
		font-size:14px;
        margin-bottom: 0px;
	}
	img.teaser_img {
		width: 256px;
		display: block;
    margin-left: auto;
    margin-right: auto;
		margin-top: 5px;
		margin-bottom: 5px;
		border: 0px solid black
	}
	img.photo_of_me {
		border-radius: 20px;
	}
	div.teaser_img_div {
		width: 286px;
	}


</style>


</head>


<body>
	<div id="container">

	<div class="section_div">
        <table id="personal_info">
        <tbody><tr>
        <td><img class="photo_of_me" src="./images/my_photo2.jpg" width="180px" style="border: 1px solid black; float:left; margin-right:15px"></td>
        <td>
        <div id="DocInfo">
            <h1>Artsiom Sanakoyeu</h1>
             <b>artsiom.sanakoyeu</b> (at) <b>iwr.uni-heidelberg</b> (dot) <b>de</b><br>
             <a href="https://scholar.google.de/citations?user=3JmMPIEAAAAJ&hl=en&oi=sra">Google Scholar</a> / <a href="https://www.linkedin.com/in/sanakoev/">LinkedIn</a> / <a href="https://github.com/asanakoy">GitHub</a> / <a href="https://www.kaggle.com/asanakoev">Kaggle</a> / <a href="/blog">Blog</a> / <a href="https://www.youtube.com/channel/UC1iTgaC4cvfIx1k27TFSfug">YouTube channel</a>
        </div><br>
        </td>
        </tr>
        </tbody></table>


        <h2>About me</h2>
        <p>
            I am a PhD student at <a href="https://hci.iwr.uni-heidelberg.de/compvis">Computer Vision</a> group at Heidelberg University under the supervision of <a href="https://hci.iwr.uni-heidelberg.de/Staff/bommer">Björn Ommer</a> and a Kaggle competitions Master (ranked Top 50 worldwide).
        </p>
	</div>
	<hr>


    <div class="section_div" id="news">
        <h2>News</h2>
        <p>&#9659; 02/2020. Our paper <a href="https://asanakoy.github.io/densepose-evolution">Transferring Dense Pose to Proximal Animal Classes</a> was accepted at CVPR 2020.</p>
	    <p>&#9659; 09/2019. I was ranked as one of the best reviewers at NeurIPS 2019 (top 400).</p>
        <p>&#9659; 09/2019. Started internship at Facebook AI Research (with Andrea Vedaldi and Natalia Neverova).</p>
        <p>&#9659; 08/2019. Our paper <a href="https://arxiv.org/abs/1904.04445">Semi-Supervised Segmentation of Salt Bodies in Seismic Images using an Ensemble of Convolutional Neural Networks</a> was accepted at GCPR 2019 [Oral].</p>
        <p>&#9659; 08/2019. Our paper <a href="https://compvis.github.io/content-style-disentangled-ST">Content and Style Disentanglement for Artistic Style Transfer</a> was accepted at ICCV 2019.</p>
        <p>&#9659; 07/2019. Invited talk at SIAM chapter in Heidelberg: Identification of Humpback Whales using Deep Metric Learning</p>
        <p>
	    &#9659; 2 papers accepted at CVPR 2019.
        </p>
        <p>
	    &#9659; My team finished 10th (out of 2131 teams) in <a href="https://www.kaggle.com/c/humpback-whale-identification/leaderboard">Humpback Whale Identification challenge</a> on Kaggle. <a href="https://twitter.com/artsiom_s/status/1101650567825375237">Tweet</a>.
	</p>
        <p>
            &#9659; Our paper <a href="https://compvis.github.io/adaptive-style-transfer">A Style-Aware Content Loss for Real-time HD Style Transfer</a> was accepted at ECCV 2018 [Oral].
        </p>
    </div>
    <hr>



<div class="section_div">

	<h2>Selected Papers</h2>

    <table class="pub_table"><tbody>
    
<!--    <tr><td class="year_heading">2018<hr></td></tr>-->
    <tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <a href="https://asanakoy.github.io/densepose-evolution"><img class="teaser_img" src="./images/teaser_cvpr20.jpg"></a>
            </div>
        </td>
		<td class="pub_td2">
            <b>Transferring Dense Pose to Proximal Animal Classes</b>
            <br>
            Artsiom Sanakoyeu, Vasil Khalidov, Maureen S. McCarthy, Andrea Vedaldi, Natalia Neverova
            <br>
            <b>CVPR 2020.</b>
            <br>
            [<a href="https://arxiv.org/pdf/2003.00080.pdf">Paper</a>] [<a href="https://asanakoy.github.io/densepose-evolution" target="_blank">Website</a>] [<a href="https://github.com/asanakoy/densepose-evolution" target="_blank">Code</a>] [<a href="https://youtu.be/ccL_ijLup4k" target="_blank">Video</a>]
        </td>
    </tr>
    <tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <a href="https://compvis.github.io/content-style-disentangled-ST"><img class="teaser_img" src="./images/teaser_iccv19_style_transfer.jpg"></a>
            </div>
        </td>
		<td class="pub_td2">
            <b>Content and Style Disentanglement for Artistic Style Transfer</b>
            <br>
            Dmytro Kotovenko, Artsiom Sanakoyeu, Sabine Lang, Björn Ommer
            <br>
            <b>ICCV 2019.</b>
            <br>
            [<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Kotovenko_Content_and_Style_Disentanglement_for_Artistic_Style_Transfer_ICCV_2019_paper.pdf">Paper</a>] [<a href="https://compvis.github.io/content-style-disentangled-ST" target="_blank">Website</a>] [<a href="https://github.com/CompVis/content-style-disentangled-ST" target="_blank">Code</a>] [<a href="https://www.youtube.com/watch?v=XqBblEngeRY&list=PLPXplX5Y1SzGOxo22bqZjV1V-_LgcmLnT&index=3&t=0s" target="_blank">Video</a>]
        </td>
    </tr>
        
    <tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <a href="https://arxiv.org/pdf/1904.04445" target="_blank"><img class="teaser_img" src="./images/self_training_pipeline.png"></a>
            </div>
        </td>
		<td class="pub_td2">
            <b>Semi-Supervised Segmentation of Salt Bodies in Seismic Images using an Ensemble of Convolutional Neural Networks</b>
            <br>
            Yauhen Babakhin, Artsiom Sanakoyeu, Hirotoshi Kitamura
            <br>
            <b>German Conference on Pattern Recognition (GCPR), 2019</b>.
            <br>
            [<a href="https://arxiv.org/pdf/1904.04445">Paper</a>] [<a href="https://github.com/ybabakhin/kaggle_salt_bes_phalanx">Code</a>]
        </td>
    </tr>
        
    <tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <a href="#"><img class="teaser_img" src="./images/teaser_cvpr19_dml.jpg"></a>
            </div>
        </td>
		<td class="pub_td2">
            <b>Divide and Conquer the Embedding Space for Metric Learning</b>
            <br>
            Artsiom Sanakoyeu, Vadim Tschernezki, Uta Büchler, Björn Ommer
            <br>
            <b>CVPR 2019.</b>
            <br>
            [<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Sanakoyeu_Divide_and_Conquer_the_Embedding_Space_for_Metric_Learning_CVPR_2019_paper.html">Paper</a>] [<a href="https://github.com/CompVis/metric-learning-divide-and-conquer">Code</a>]
        </td>
    </tr>
        
    <tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <a href="https://compvis.github.io/content-targeted-style-transfer"><img class="teaser_img" src="./images/teaser_cvpr19_style_transfer.jpg"></a>
            </div>
        </td>
		<td class="pub_td2">
            <b>A Content Transformation Block for Image Style Transfer</b>
            <br>
            Dmytro Kotovenko, Artsiom Sanakoyeu, Pingchuan Ma, Sabine Lang, Björn Ommer
            <br>
            <b>CVPR 2019.</b>
            <br>
            [<a href="https://arxiv.org/pdf/2003.08407">Paper</a>] [<a href="https://compvis.github.io/content-targeted-style-transfer">Website</a>] [<a href="https://github.com/CompVis/content-targeted-style-transfer">Code</a>]
        </td>
    </tr>
        
	<tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <a href="https://compvis.github.io/adaptive-style-transfer"><img class="teaser_img" src="./images/teaser_eccv18.jpg"></a>
            </div>
        </td>
		<td class="pub_td2">
            <b>A Style-Aware Content Loss for Real-time HD Style Transfer</b>
            <br>
            Artsiom Sanakoyeu*, Dmytro Kotovenko*, Sabine Lang, Björn Ommer
            <br>
            <b>ECCV 2018 (Oral).</b>
            <br>
            [<a href="http://arxiv.org/pdf/1807.10201">Paper</a>] [<a href="https://compvis.github.io/adaptive-style-transfer">Website</a>] [<a href="https://github.com/CompVis/adaptive-style-transfer">Code</a>]
        </td>
    </tr>
        
    <tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <img class="teaser_img" src="./images/teaser_pr_2018.jpg">
            </div>
        </td>
		<td class="pub_td2">
            <b>Deep Unsupervised Learning of Visual Similarities</b>
            <br>
            Artsiom Sanakoyeu, Miguel Bautista, Björn Ommer
            <br>
            <b> Pattern Recognition. 78, 2018</b>.
            <br>[<a href="https://hci.iwr.uni-heidelberg.de/sites/default/files/publications/files/234934243/deep_unsupervised_learning_of_visual_similarities_pr_2018.pdf">Paper</a>] [<a href="https://hci.iwr.uni-heidelberg.de/node/6229">Website</a>]
        </td>
    </tr>


<!--    <tr><td class="year_heading"><br>2017<hr></td></tr>-->
    <tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <img class="teaser_img" src="./images/teaser_cvpr2017.png">
            </div>
        </td>
		<td class="pub_td2">
            <b>Deep Unsupervised Similarity Learning using Partially Ordered Sets</b>
            <br>
            Miguel Bautista*, Artsiom Sanakoyeu*, Björn Ommer
            <br>
            <b> CVPR 2017</b>.
            <br>[<a href="https://arxiv.org/pdf/1704.02268">Paper</a>] [<a href="https://github.com/asanakoy/deep_unsupervised_posets">Code</a>]
            
        </td>
    </tr>


<!--    <tr><td class="year_heading"><br>2016<hr></td></tr>-->
    <tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <img class="teaser_img" src="./images/teaser_cliquecnn_400.png">
            </div>
        </td>
		<td class="pub_td2">
            <b>CliqueCNN: Deep Unsupervised Exemplar Learning</b>
            <br>
            Miguel Bautista*, Artsiom Sanakoyeu*, Björn Ommer
            <br>
            <b>NIPS 2016</b>.
            <br>[<a href="https://arxiv.org/pdf/1608.08792">Paper</a>] [<a href="https://asanakoy.github.io/cliquecnn/">Website</a>] [<a href="http://www.viewserv.de/EMVA-Forum/4347_bm5jMuD7KqY3UKD62Rv1/7077.html#7077">Video Presentation</a>] [<a href="https://github.com/asanakoy/cliquecnn">Code</a>]
            
        </td>
<!--        TODO: add supllementary-->
    </tr>

	

	</tbody></table>
    
<!--
    <h2>Preprints</h2>

    <table class="pub_table"><tbody>

    
	</tbody></table>
-->
    
    
    <h2>Other Projects</h2>
    <table class="pub_table"><tbody>
    <tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <img class="teaser_img" src="./images/teaser_kaggle_lyft_2020.jpg">
            </div>
        </td>
        <td class="pub_td2">

            <b> 3st place: Lyft Motion Prediction for Autonomous Vehicles on Kaggle</b>

            <br>
            Problem:  build a model that reliably predicts the movement of traffic agents around the Autonomous Vehicle, such as cars, cyclists, and pedestrians.
            <br>
            <i><b>3rd place out of 935</b> teams, <a href="https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles/leaderboard" target="_blank">Kaggle.com</a>, 2020</i>
            <br>
            [<a href="https://gdude.de/blog/2021-02-05/Kaggle-Lyft-solution">Blogpost</a>] [<a href="https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles/leaderboard" target="_blank">Leaderboard</a>] [<a href="https://github.com/asanakoy/kaggle-lyft-motion-prediction-av">Code</a>] [<a href="https://youtu.be/3Yz8_x38qbc">Video</a>] 
        </td>
    </tr>
        
	<tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <img class="teaser_img" src="./images/teaser_kaggle_carvana.png">
            </div>
        </td>
		<td class="pub_td2">

            <b> 1st place: Carvana Image Masking Challenge on Kaggle</b>

            <br>
            Carvana, a successful online used car startup, challenged the Kaggle community to develop an algorithm that automatically removes the photo background.
            <br>
            <i><b>1st place out of 735</b> participants, <a href="https://www.kaggle.com/c/carvana-image-masking-challenge/leaderboard" target="_blank">Kaggle.com</a>, 2017</i>
            <br>
            [<a href="https://medium.com/kaggle-blog/carvana-image-masking-challenge-1st-place-winners-interview-78fcc5c887a8">Blogpost</a>] [<a href="https://www.kaggle.com/c/carvana-image-masking-challenge/leaderboard" target="_blank">Leaderboard</a>] [<a href="https://github.com/asanakoy/kaggle_carvana_segmentation">Code</a>]
        </td>
    </tr>
    </tbody></table>

    <h2>Invited Talks</h2>
    <table class="pub_table"><tbody>
	<tr>
        <td class="pub_td1">
            <div class="teaser_img_div">
                <img class="teaser_img" src="./images/train_whales_grid_800_480.jpg">
            </div>
        </td>
		<td class="pub_td2">

            <b> Identification of Humpback Whales using Deep Metric Learning</b>

            <br>
            <i>Society for Industrial and Applied Mathematics (SIAM), Heidelberg, July 2019</i>
            <br>
            [<a href="https://slides.com/asanakoy/metric-learning-kaggle-whales" target="_blank">Slides</a>]
        </td>
    </tr>
    </tbody></table>
    
</div>
        
<h2>Review activities</h2>
<p> NeurIPS (<b>Best Reviewer 2020, 2019</b>), ICLR, ICCV, CVPR, ECCV, SIGGRAPH, IEEE Transactions on Image Processing </p>


</div></body></html>
